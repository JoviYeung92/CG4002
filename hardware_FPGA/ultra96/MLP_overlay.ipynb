{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP IP implemented in HLS via DMA.\n",
    "\n",
    "\n",
    "Better features(instead of the raw accelerometer data) and training data can probably be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import DefaultIP\n",
    "from pynq import allocate\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "inputs = [-43,-35,-300,300,-41,-30,-295,305,-42,-32,\n",
    "            -297,302,0,3,2,2,0,1,1,1,0,0,0,0,42,32,297,\n",
    "            302,1,1,12,12,70,39,3386,3496,8,6,58,59] \n",
    "#input is a zig zag feature set, index 2 in the output array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP CPU IMPLEMENTATION(Quantized ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502470 976993 -499376 \n",
      "\n",
      "8.601ms\n",
      "Overhead 654.2484760284424 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "! ./MLPInference << ./input_weights.txt\n",
    "print(\"Overhead\" ,(time.time() - start_time) * 1000 , 'ms') #overhead in launching program through notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS IMPLEMENTATION(Area/ Power optimal on PL)\n",
    "The custom IP is communicated to via DMA.\n",
    "\n",
    "It is used to accelerate the calculations of the euclidian distance of the acceleration data.\n",
    "\n",
    "The first result is the distance between ZigZag, the second is rocket, the third is head.\n",
    "\n",
    "The 4th number is padding.\n",
    "<img src=\"./files/MLP_No_Optimizations_util.png\">\n",
    "<img src=\"./files/MLP_No_Optimizations_power.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Bitstream file /home/xilinx/impl_2/design_1.bit does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a28d26ecd86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moverlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOverlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/xilinx/impl_2/design_1.bit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pynq/overlay.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bitfile_name, dtbo, download, ignore_version, device)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbitfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bitfile_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pynq/bitstream.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bitfile_name, dtbo, partial, device)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             raise IOError('Bitstream file {} does not exist.'.format(\n\u001b[0;32m--> 107\u001b[0;31m                 bitfile_name))\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtbo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Bitstream file /home/xilinx/impl_2/design_1.bit does not exist."
     ]
    }
   ],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_2/design_1.bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma = overlay.axi_dma_0            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "out_buffer\n",
    "print((time.time() - start_time) * 1000 , 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## HLS IMPLEMENTATION(Dataflow optimization on all layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_dataflow/design_1.bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma = overlay.axi_dma_0            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "print((time.time() - start_time) * 1000 , 'ms')\n",
    "print(out_buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS IMPLEMENTATION(Unroll directive on first(128 factor) and last layers(32))\n",
    "\n",
    "<img src=\"./files/MLP_Unroll_128_0_full.png\">\n",
    "\n",
    "\n",
    "<img src=\"./files/MLP_Unroll_0_128_Full_power.png\">\n",
    "\n",
    "8% more LUTS, 2.6W vs 2.4W (~8% of power increase)\n",
    "Non pareto optimal due to the next implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_unroll/design_1.bit')\n",
    "dma = overlay.axi_dma_0            \n",
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)\n",
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "print((time.time() - start_time) * 1000 , 'ms')\n",
    "print(out_buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS IMPLEMENTATION(Unroll directive on first(32 factor) second(64) and last layers(32))\n",
    "\n",
    "<img src=\"./files/MLP_Unroll_32_64_32.png\">\n",
    "<img src=\"./files/MLP_Unroll_32_64_32_Power.png\">\n",
    "\n",
    "Power and Area in between minimal area implementation and 128 factor on first layer(Prev implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_32_64_32/design_1.bit')\n",
    "dma = overlay.axi_dma_0            \n",
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)\n",
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "print((time.time() - start_time) * 1000 , 'ms')\n",
    "print(out_buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## HLS IMPLEMENTATION(Unroll directive on first(64 factor) second(128) and last layers(32))\n",
    "\n",
    "<img src=\"./files/MLP_Unroll_64_128_32.png\">\n",
    "<img src=\"./files/MLP_Unroll_64_128_32_Power.png\">\n",
    "\n",
    "Much higher resource usuage (LUTS)for not much performance increase, but nontherless still pareto-optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_64_128_32/design_1.bit')\n",
    "dma = overlay.axi_dma_0            \n",
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)\n",
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "print((time.time() - start_time) * 1000 , 'ms')\n",
    "print(out_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Implementation with 40 features\n",
    "\n",
    "The outputs are the distance to the closest neighbour of the type i.e k = 1;\n",
    "The closest is the prediction of the feature set.\n",
    "\n",
    "## CPU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "! ./KNNInference < input_weights.txt\n",
    "print(\"Overhead\" ,(time.time() - start_time) * 1000 , 'ms') #overhead in launching program through notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS Implementation of KNN (No optimisations)\n",
    "<img src=\"./files/KNN_No_Optimisation.png\">\n",
    "\n",
    "Without optimisations, KNN has a lower area usage and power usage as compared to MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_knn_no_optimisations/design_1.bit')\n",
    "dma = overlay.axi_dma_0            \n",
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)\n",
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "print((time.time() - start_time) * 1000 , 'ms')\n",
    "print(out_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS Implementation of KNN (unroll 32)\n",
    "<img src=\"./files/KNN_32.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/impl_knn/design_1.bit')\n",
    "dma = overlay.axi_dma_0            \n",
    "in_buffer = allocate(shape=(40,), dtype=np.int32)\n",
    "for i in range(40):\n",
    "    in_buffer[i] = inputs[i];\n",
    "out_buffer = allocate(shape=(4,), dtype=np.int32)\n",
    "start_time = time.time()\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "print((time.time() - start_time) * 1000 , 'ms')\n",
    "print(out_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
