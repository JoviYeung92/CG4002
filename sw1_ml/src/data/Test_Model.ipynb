{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.2 64-bit",
   "display_name": "Python 3.6.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e6adf29cef8b061b341cb433c300a676913b4f582f04207333fdbe5b7280c514"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## First version of ML model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from load_data import load_dance_data\n",
    "from load_data import one_hot_encoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files read from  Hair.txt\n",
      "Files read from  Rocket.txt\n",
      "Files read from  Zig_Zag.txt\n"
     ]
    }
   ],
   "source": [
    "# dataset = 'C:\\\\Users\\\\shrey\\\\Desktop\\\\NUS- Everything\\\\Semester 7\\\\CG4002\\\\CG4002_B18\\\\sw1_ml\\\\data\\\\processed\\\\'\n",
    "\n",
    "dataset = os.getcwd() + '\\\\Dance_data\\\\'\n",
    "\n",
    "sampling_rate = 5\n",
    "window_size = 2.56\n",
    "\n",
    "X, y = load_dance_data(dataset, sampling_rate, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, X_test = X[:int(len(X)*0.8), :], X[int(len(X)*0.8):, :]\n",
    "y_train, y_test = y[:int(len(X)*0.8), :], y[int(len(X)*0.8):, :]\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_train = y_train.reshape(y_train.shape[0]).long()\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "y_test = y_test.reshape(y_test.shape[0]).long()\n",
    "\n",
    "input_size = X.shape[1]\n",
    "output_size = one_hot_encoder(y).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_states = [256, 128]\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_states[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_states[0], hidden_states[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_states[1], output_size),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training and testing\n",
    "import torch.utils.data\n",
    "\n",
    "class Prepare_data(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.inputs[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(Prepare_data(X_train, y_train), batch_size=32, shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(Prepare_data(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training loss: 184.7803331392152\nTraining loss: 1.0217469811439515\nTraining loss: 0.9954640456608363\nTraining loss: 0.9989692143031529\nTraining loss: 0.7252138529505049\nTraining loss: 0.5522320704800742\nTraining loss: 0.5006617035184587\nTraining loss: 2.4122658865792412\nTraining loss: 1.0826406734330314\nTraining loss: 2.0484613180160522\nTraining loss: 1.06397511107581\nTraining loss: 1.0354888473238264\nTraining loss: 1.0238720434052604\nTraining loss: 1.2717085804258075\nTraining loss: 1.0202201758112226\n"
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for inputs, labels in trainloader:\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test)\n",
    "\n",
    "y_pred = y_pred.cpu()\n",
    "result = y_pred.data.numpy()\n",
    "array_res = np.reshape(result, (1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.94 Avg loss: 0.18\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.95 Avg loss: 0.18\n",
      "Training Results - Epoch: 2  Avg accuracy: 1.00 Avg loss: 0.01\n",
      "Validation Results - Epoch: 2  Avg accuracy: 1.00 Avg loss: 0.01\n",
      "Training Results - Epoch: 3  Avg accuracy: 1.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 3  Avg accuracy: 1.00 Avg loss: 0.00\n",
      "Training Results - Epoch: 4  Avg accuracy: 1.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 4  Avg accuracy: 1.00 Avg loss: 0.00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 140\n",
       "\tepoch: 4\n",
       "\tepoch_length: 35\n",
       "\tmax_epochs: 35\n",
       "\toutput: 0.00020066721481271088\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['crossentropy']\n",
    "    accuracy = engine.state.metrics['accuracy']\n",
    "    return accuracy\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, loss)\n",
    "evaluator = create_supervised_evaluator(model,\n",
    "                                        metrics={\n",
    "                                            'accuracy': Accuracy(),\n",
    "                                            'crossentropy': Loss(loss)\n",
    "                                            })\n",
    "\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n",
    "# Note: the handler is attached to an *Evaluator* (runs one epoch on validation dataset).\n",
    "evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(trainloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['crossentropy']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(testloader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['crossentropy']))\n",
    "\n",
    "trainer.run(trainloader, max_epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"NN_v1_3moves.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of the network on the test inputs: 100 %\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test inputs: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GroundTruth:   Hair  Hair  Hair Rocket Zig-Zag Rocket Zig-Zag  Hair  Hair  Hair Zig-Zag  Hair  Hair  Hair Rocket  Hair  Hair Zig-Zag Rocket  Hair Zig-Zag  Hair Zig-Zag  Hair Zig-Zag  Hair  Hair  Hair Rocket Rocket Rocket  Hair\nPredicted:     Hair  Hair  Hair Rocket Zig-Zag Rocket Zig-Zag  Hair  Hair  Hair Zig-Zag  Hair  Hair  Hair Rocket  Hair  Hair Zig-Zag Rocket  Hair Zig-Zag  Hair Zig-Zag  Hair Zig-Zag  Hair  Hair  Hair Rocket Rocket Rocket  Hair\n"
    }
   ],
   "source": [
    "classes = ['Hair', 'Rocket', 'Zig-Zag']\n",
    "dataiter = iter(testloader)\n",
    "inputs, labels = dataiter.next()\n",
    "\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(len(labels))))\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted:   ', ' '.join('%5s' % classes[predicted[j]] for j in range(len(labels))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=40, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=3, bias=True)\n  (5): LogSoftmax()\n)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "first_model = model\n",
    "first_model.load_state_dict(torch.load(\"NN_v1_3moves.pt\"))\n",
    "first_model.eval()"
   ]
  },
  {
   "source": [
    "## Next Steps\n",
    "\n",
    "* Employ additional Machine Learning Models and test out the accuracy obtained\n",
    "* Update the feature extraction process to include better measures as well as the Gyroscope data\n",
    "* Apply preprocessing on the dataset to remove noise\n",
    "* Run the models on the online dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}